# 场景应用



## 缓存

在大型系统中，为了减少数据库压力通常会引入缓存机制，一旦引入缓存又很容易造成缓存和数据库数据不一致，导致用户看到的是旧数据。

为了减少数据不一致的情况，更新缓存和数据库的机制显得尤为重要。

### 缓存策略

缓存更新的策略主要分为三种：

- Cache aside
- Read/Write through
- Write behind

Cache aside 通常会先更新数据库，然后再删除缓存，为了兜底通常还会将数据设置缓存时间。

Read/Write through 一般是由一个 Cache Provider 对外提供读写操作，应用程序不用感知操作的是缓存还是数据库。

Write behind简单理解就是延迟写入，Cache Provider 每隔一段时间会批量输入数据库，优点是应用程序写入速度非常快。

![](https://images.yingwai.top/picgo/20210818173038.jpg)

#### Cache aside

`Cache aside` 也就是**旁路缓存**，是比较常用的缓存策略。

##### 读请求常见流程

![](https://images.yingwai.top/picgo/20210818173242.png)

应用首先会判断缓存是否有该数据，缓存命中直接返回数据，缓存未命中即缓存穿透到数据库，从数据库查询数据然后回写到缓存中，最后返回数据给客户端。

##### 写请求常见流程

![](https://images.yingwai.top/picgo/20210818173325.png)

首先更新数据库，然后从缓存中删除该数据。

为什么要删除缓存，直接更新不就行了？这里涉及到几个坑，一步一步踩下去。

##### Cache aside 踩坑

Cache aside策略如果用错就会遇到深坑，下面来逐个踩。

###### 踩坑一：先更新数据库，再更新缓存

如果同时有两个**写请求**需要更新数据，每个写请求都先更新数据库再更新缓存，在并发场景可能会出现数据不一致的情况。

![](https://images.yingwai.top/picgo/20210818173409.png)

如上图的执行过程：

1. `写请求1`更新数据库，将 age 字段更新为18；
2. `写请求2`更新数据库，将 age 字段更新为20；
3. `写请求2`更新缓存，缓存 age 设置为20；
4. `写请求1`更新缓存，缓存 age 设置为18；

执行完预期结果是数据库 age 为20，缓存 age 为20，结果缓存 age 为18，这就造成了缓存数据不是最新的，出现了脏数据。

###### 踩坑二：先删缓存，再更新数据库

如果**写请求**的处理流程是**先删缓存再更新数据库**，在一个**读请求**和一个**写请求**并发场景下可能会出现数据不一致情况。

![](https://images.yingwai.top/picgo/20210818173422.jpg)

如上图的执行过程：

1. `写请求`删除缓存数据；
2. `读请求`查询缓存未击中(Hit Miss)，紧接着查询数据库，将返回的数据回写到缓存中；
3. `写请求`更新数据库。

整个流程下来发现`数据库`中age为20，`缓存`中age为18，缓存和数据库数据不一致，缓存出现了脏数据。

###### 踩坑三：先更新数据库，再删除缓存

在实际的系统中针对**写请求**还是推荐**先更新数据库再删除缓存**，但是在理论上还是存在问题，以下面这个例子说明。

![](https://images.yingwai.top/picgo/20210818173434.png)

如上图的执行过程：

1. `读请求`先查询缓存，缓存未击中，查询数据库返回数据；
2. `写请求`更新数据库，删除缓存；
3. `读请求`回写缓存；

整个流程操作下来发现`数据库age为20`，`缓存age为18`，即数据库与缓存不一致，导致应用程序从缓存中读到的数据都为旧数据。

但我们仔细想一下，上述问题发生的概率其实非常低，因为通常数据库更新操作比内存操作耗时多出几个数量级，上图中最后一步回写缓存（set age 18）速度非常快，通常会在更新数据库之前完成。

如果这种极端场景出现了怎么办？我们得想一个兜底的办法：`缓存数据设置过期时间`。通常在系统中是可以允许少量的数据短时间不一致的场景出现。

#### Read through

在 Cache Aside 更新模式中，应用代码需要维护两个数据源头：一个是缓存，一个是数据库。而在 Read-Through 策略下，应用程序无需管理缓存和数据库，只需要将数据库的同步委托给缓存提供程序 Cache Provider 即可。所有数据交互都是通过抽象缓存层完成的。

![](https://images.yingwai.top/picgo/20210818173447.jpg)

如上图，应用程序只需要与`Cache Provider`交互，不用关心是从缓存取还是数据库。

在进行大量读取时，`Read-Through` 可以减少数据源上的负载，也对缓存服务的故障具备一定的弹性。如果缓存服务挂了，则缓存提供程序仍然可以通过直接转到数据源来进行操作。

`Read-Through 适用于多次请求相同数据的场景`，这与 Cache-Aside 策略非常相似，但是二者还是存在一些差别，这里再次强调一下：

- 在 Cache-Aside 中，应用程序负责从数据源中获取数据并更新到缓存。
- 在 Read-Through 中，此逻辑通常是由独立的缓存提供程序（Cache Provider）支持。

#### Write through

`Write-Through` 策略下，当发生数据更新(Write)时，缓存提供程序 `Cache Provider` 负责更新底层数据源和缓存。

缓存与数据源保持一致，并且写入时始终通过`抽象缓存层`到达数据源。

`Cache Provider`类似一个代理的作用。

![](https://images.yingwai.top/picgo/20210818173459.png)

#### Write behind

`Write behind`在一些地方也被成为`Write back`， 简单理解就是：应用程序更新数据时只更新缓存， `Cache Provider`每隔一段时间将数据刷新到数据库中。说白了就是延迟写入。

![](https://images.yingwai.top/picgo/20210818173513.jpg)

如上图，应用程序更新两个数据，Cache Provider 会立即写入缓存中，但是隔一段时间才会批量写入数据库中。

这种方式有优点也有缺点：

- `优点`是数据写入速度非常快，适用于频繁写的场景。
- `缺点`是缓存和数据库不是强一致性，对一致性要求高的系统慎用。



## 分布式锁

在系统中修改已有数据时，需要先读取，然后进行修改保存，此时很容易遇到并发问题。由于修改和保存不是原子操作，在并发场景下，部分对数据的操作可能会丢失。在单服务器系统我们常用本地锁来避免并发带来的问题，然而，当服务采用集群方式部署时，本地锁无法在多个服务器之间生效，这时候保证数据的一致性就需要分布式锁来实现。

锁是计算机领域一个非常常见的概念，分布式锁也依赖存储组件，针对请求量的不同，可以选择Etcd、MySQL、Redis等。前两者可靠性更强，Redis性能更高。

![](https://images.yingwai.top/picgo/20210726221237.png)

### 实现

想要实现分布式锁，必须要求 Redis 有「互斥」的能力，我们可以使用 SETNX 命令，这个命令表示**SET** if **N**ot e**X**ists，即如果 key 不存在，才会设置它的值，否则什么也不做。

两个客户端进程可以执行这个命令，达到互斥，就可以实现一个分布式锁：

```shell
SETNX lock 1
(integer) 1		// 客户端1加锁成功

SETNX lock 1
(integer) 0		// 客户端2申请加锁，因为后到达，加锁失败
```

操作完成后还要及时释放锁：

```shell
DEL lock 		// 释放锁
(integer) 1
```

![](https://images.yingwai.top/picgo/20210726222219.jpg)

### 死锁

上面的步骤存在一个很大的问题，当客户端 1 拿到锁后，如果发生下面的场景，就会造成「死锁」：

1. 程序处理业务逻辑异常，没及时释放锁
2. 进程挂了，没机会释放锁

这时，这个客户端就会一直占用这个锁，而其它客户端就「永远」拿不到这把锁了。

#### 避免死锁

上述问题的解决方案也很简单，在申请锁时设置一个过期时间即可。注意这里不能把获取锁和设置过期时间的命令分开，避免出现获取锁成功但由于服务器宕机或网络等问题造成 `EXPIRE` 命令没有执行的极端情况出现，因此要使用 `SET lock EX 10 NX` 命令。

但这种场景下还是存在问题：

1. 客户端 1 加锁成功，开始操作共享资源
2. 客户端 1 操作共享资源的时间，「超过」了锁的过期时间，锁被「自动释放」
3. 客户端 2 加锁成功，开始操作共享资源
4. 客户端 1 操作共享资源完成，释放锁（但释放的是客户端 2 的锁）

### 锁过期

锁过期产生的原因是当前客户端操作共享资源耗时太久，导致锁被自动释放，之后被别的客户端持有。

容易想到事先预估某个操作需要执行的时间，然后根据这个预估的时间来设置过期时间。这样确实可以缓解锁过期的问题，降低出问题的概率，但无法彻底解决问题。

比较好的方法是：**加锁时，先设置一个过期时间，然后我们开启一个「守护线程」，定时去检测这个锁的失效时间，如果锁快要过期了，操作共享资源还未完成，那么就自动对锁进行「续期」，重新设置过期时间。**Redisson 就封装好了这些工作。

![](https://images.yingwai.top/picgo/20210727172117.jpg)

### 锁被别人释放

在死锁那里提到，潜在的问题还有客户端 1 操作共享资源完成后，却又释放了客户端 2 的锁。这种情况的解决方法是**在加锁时，设置一个只有自己知道的「唯一标识」进去**：

```shell
// 锁的VALUE设置为UUID
127.0.0.1:6379> SET lock $uuid EX 20 NX
OK
```

然后释放时要判断锁是否是自己持有，是才进行释放（伪代码）：

```java
if (redis.get("lock") == $uuid) {
    redis.del("lock");
}
```

因为这里是两条命令，因此为了保证原子性，可以借助Lua脚本来执行。因为 Redis 处理每一个请求是「单线程」执行的，在执行一个 Lua 脚本时，其它请求必须等待，直到这个 Lua 脚本处理完成，这样一来，GET + DEL 之间就不会插入其它命令了。

### 主从发生切换

1. 客户端 1 在主库上执行 SET 命令，加锁成功
2. 此时，主库异常宕机，SET 命令还未同步到从库上（主从复制是异步的）
3. 从库被哨兵提升为新主库，这个锁在新的主库上，丢失了！

针对这个问题，Redis 作者提出了 **Redlock**。



**参考链接：**

* [分布式锁的实现之 redis 篇](https://xiaomi-info.github.io/2019/12/17/redis-distributed-lock/)
* [深度剖析：Redis分布式锁到底安全吗？看完这篇文章彻底懂了！](http://kaito-kidd.com/2021/06/08/is-redis-distributed-lock-really-safe/)



## 布隆过滤器

布隆过滤器底层是一个64位的整型（bitmap），将字符串用多个Hash函数映射不同的二进制位置，将整型中对应位置设置为1。

在查询的时候，如果一个字符串所有Hash函数映射的值都存在，那么数据可能存在。为什么说可能呢，就是因为其他字符可能占据该值，提前点亮。

可以看到，布隆过滤器优缺点都很明显，优点是空间、时间消耗都很小，缺点是结果不是完全准确。

![](https://images.yingwai.top/picgo/202108172112093.png)

### 扩容/删除过期数据

布隆过滤器是不可变的，但如果布隆过滤器容量确实不够了，该怎么办呢？或者如果要每个月都删除几个月前的去重数据，该如何处理呢？这边要记录一种布隆过滤器的巧用，多个布隆过滤器组成的循环布隆过滤器。

#### 布隆过滤器扩容

因为布隆过滤器的不可逆，我们没法重新建一个更大的布隆过滤器然后去把数据重新导入。这边采取的扩容的方法是，保留原有的布隆过滤器，建立一个更大的，新增数据都放在新的布隆过滤器中，去重的时候检查所有的布隆过滤器。

非常巧妙的方法，用一个新的布隆过滤器和多个老的布隆过滤器共同组成一个新的过滤器，提供相同的接口。

#### 附带时效的布隆过滤器

可以考虑使用多个布隆过滤器滚动，比如数据每三个月清空一次，那么就可以维护三个布隆过滤器。每次插入都插入到所有的布隆过滤器中，每次查询都从最旧的那个布隆过滤器中查，然后每个月把最旧的布隆过滤器清空，使它变为最新的。这样做可以实现布隆过滤器中数据的过期。

